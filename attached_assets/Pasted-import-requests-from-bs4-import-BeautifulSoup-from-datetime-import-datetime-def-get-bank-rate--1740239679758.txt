import requests
from bs4 import BeautifulSoup
from datetime import datetime

def get_bank_rate():
    url = "https://www.bankofengland.co.uk/boeapps/database/Bank-Rate.asp"
    
    try:
        # Get the webpage content with necessary cookies
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # Create a session to handle cookies
        session = requests.Session()
        
        # Set cookies to bypass consent
        cookies = {
            'cookie_consent': 'accepted',
            'cookie_consent_essential': 'accepted',
            'cookie_consent_analytics': 'accepted'
        }
        
        # Make request with cookies
        response = session.get(url, headers=headers, cookies=cookies)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Find the table with the rates
            table = soup.find('table')
            if table:
                # Get the first row (most recent rate)
                latest_row = table.find_all('tr')[1]  # Skip header row
                cells = latest_row.find_all('td')
                
                date = cells[0].text.strip()
                rate = cells[1].text.strip()
                
                print("\nUK Bank Rate:")
                print("-" * 30)
                print(f"Current Rate: {rate}%")
                print(f"Effective Date: {date}")
                print(f"Last checked: {datetime.now().strftime('%Y-%m-%d')}")
            else:
                print("Could not find rate table on the page")
            
        else:
            print(f"Error accessing Bank of England website: Status code {response.status_code}")
            print("Response content:", response.text[:500])  # Print first 500 chars of response for debugging
            
    except Exception as e:
        print(f"Error: {str(e)}")

get_bank_rate()